{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_01_813479 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plrqRvUQwJqG"
      },
      "source": [
        "# Digital Signal and Image Management\n",
        "###### Assignment 1\n",
        "\n",
        "\n",
        "> **Cognome**: Sofia    **Nome**: Davoli                                  \\\\\n",
        "> **Matricola**: 813479                                                     \\\\\n",
        "                                   \\\\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UJ8A1AqwzvM"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgH-TVlvwIbA"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from time import time\n",
        "from scipy.io import wavfile as wav\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "#-- Classification Tools\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#-- File Management\n",
        "from google.colab import drive\n",
        "import tarfile\n",
        "from shutil import copyfile\n",
        "\n",
        "#-- Advanced Audio Features\n",
        "import librosa\n",
        "import librosa.display as lid\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-3B6zv7xG4R"
      },
      "source": [
        "## Files Reading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H4QGGJ6yGYt"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yheAcmahyNrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9422401-ec3c-4a85-da96-c6785a4ffd32"
      },
      "source": [
        "#@title Copia del File `recording.tar` {display-mode: \"form\"}\n",
        "\n",
        "copyfile(\"gdrive/My Drive/dsim_material_E02/recordings.tar\", \"recordings.tar\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'recordings.tar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeGj3ZAyyfIx"
      },
      "source": [
        "tar = tarfile.open(\"recordings.tar\")\n",
        "tar.extractall()  #extract all files\n",
        "tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6if2hRpy0Yy"
      },
      "source": [
        "## Functions definition\r\n",
        "\r\n",
        "- load_data functions take in input a parameter to specify which features to extract when loading data, this will be used when creating training and test sets.\r\n",
        "\r\n",
        "- 6 different features extaction functions (aavg, sdev, duration, energy, zcr and mfcc)\r\n",
        "\r\n",
        "- 2 combo function to extract features all in one time ( this 2 functions differs for 1 features extraction method: ZCR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UldQGbZ_yyDK"
      },
      "source": [
        "#-- Placecholder per estrarre le Feature\n",
        "def identity(input):\n",
        "    return input\n",
        "\n",
        "# Data loader\n",
        "def load_data(feature_extractor = identity, normalize = False):\n",
        "\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    for f in sorted(os.listdir('./recordings')):\n",
        "        if f.endswith('.wav'):\n",
        "            #-- Caricare i File e Calcolo delle Esplicative\n",
        "            _, signal = wav.read('./recordings/' + f)\n",
        "            cur_features = feature_extractor(signal)\n",
        "            features.append(cur_features)\n",
        "\n",
        "            #-- Classi\n",
        "            label = f.split('_')[0]\n",
        "            labels.append(label)\n",
        "\n",
        "    #-- X: Variabili Esplicative, y: Risposta\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
        "                                                        test_size = 0.1,\n",
        "                                                        random_state = 1)\n",
        "\n",
        "    if normalize:\n",
        "        eps = 0.001\n",
        "        X_train = np.array(X_train)\n",
        "        X_train_mean = X_train.mean(axis = 0)\n",
        "        X_train_std = X_train.std(axis = 0)\n",
        "        X_train = (X_train - X_train_mean + eps)/(X_train_std + eps)\n",
        "        X_train = [row for row in X_train]\n",
        "\n",
        "        X_test = [row for row in (np.array(X_test) - X_train_mean + eps)/(X_train_std + eps)]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LokRM9EozdGC"
      },
      "source": [
        "def crop(input, size = 100):\n",
        "  output = input[0 : min(size, input.shape[0])]\n",
        "  output = np.concatenate((output, np.zeros(size - output.shape[0])))\n",
        "  return output\n",
        "\n",
        "def energy(input):\n",
        "    return np.sum((input*1.0)**2, keepdims=True)\n",
        "\n",
        "def sdev(input):\n",
        "    return np.std(input, keepdims = True)\n",
        "\n",
        "def aavg(input):\n",
        "    return np.mean(np.abs(input), keepdims = True)\n",
        "\n",
        "def duration(input):\n",
        "    return input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl8sG1Esz_0J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timabWzC0Ji-"
      },
      "source": [
        " ***Z***ero ***C***rossing ***R***ate (**ZCR**): The zero-crossing rate of an audio frame (or more in general of a signal) is the rate of sign-changes of the signal during the frame. In other words, it is the number of times the signal changes value, from positive to negative and vice versa, divided by the length of the frame.\r\n",
        "\r\n",
        "\r\n",
        "Function implemented take as input a signal and return ZCR value: \r\n",
        " - np.signbit function return an array of TRUE - FALSE (TRUE if number is positive, FALSE if negative)\r\n",
        " - np.where(np.diff()) this joined numpy functions allows to get the positions in the array where there are changes between TRUE - FALSE (previous value is positive and next is negative and viceversa). this return a list whith an array inside which have to be extracted using [0] command.\r\n",
        " - finally the shape of the array is extracted. this shape represent the number of changing of sign in the signal.\r\n",
        " - since an array is needed to be returned, np.array is applied to the first value of the shape (number of sign changes) and since a RATE is needed the ZERO CROSSING times value is divided by the lenght (shape[0]) of the signal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22v4lSyS0ji4"
      },
      "source": [
        "def zcr(input):\n",
        "  x = np.where(np.diff(np.signbit(input)))[0].shape  \n",
        "  return np.array([x[0]])/signal.shape[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLLL7lzL0Vyq"
      },
      "source": [
        "def mfcc(input, rate=8000, min_len=40, sampling=1):\r\n",
        "    \r\n",
        "    signal = input[::sampling] #-- Valori Campionati\r\n",
        "    \r\n",
        "    mfcc = librosa.feature.mfcc(signal*1.0, sr = int(rate/sampling)) #-- Calcolo Coefficienti MFCC\r\n",
        "    \r\n",
        "    pad_width = min_len - mfcc.shape[1] #-- Aggiunta 0 necessari per Lunghezza Equa\r\n",
        "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode = 'constant')\r\n",
        "\r\n",
        "    #-- Flatten into monodimensional vector for the SVM\r\n",
        "    mfcc = mfcc.flatten()\r\n",
        "    return mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HrguKAb1I0T"
      },
      "source": [
        "def combo(input):\n",
        "    return np.concatenate((aavg(input), sdev(input),\n",
        "                           duration(input), energy(input)))\n",
        "\n",
        "def combo_con_zcr(input):\n",
        "    return np.concatenate((aavg(input), sdev(input),\n",
        "                           duration(input), energy(input),\n",
        "                           zcr(input)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw8Tpptc1gyE"
      },
      "source": [
        "## Model Training\n",
        "SVM model is used to train and test model whithout  ZCR feature. Results of this models will be compared with the same model's result obtained including ZCR feature, and with the same model trained using mfcc features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8joT9Rx2BO8"
      },
      "source": [
        "### SVM without ZCR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkwaTt2A2Gzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad80944-218a-4eb2-f182-825fae7ee42d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor = combo,\n",
        "                                             normalize = True)\n",
        "\n",
        "#-- Dimensionalità delle Variabili Esplicative\n",
        "X_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceb1oDe129Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7d405a-e54c-4514-fc47-a6c9b9923fe5"
      },
      "source": [
        "#-- Parametri da Testare nella Cross-Validation\n",
        "param_grid = {'C': [1e2, 5e2, 1e3],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "#-- Inizializzatore della Support Vector Machine\n",
        "clf = GridSearchCV(SVC(kernel = 'rbf',\n",
        "                       class_weight = 'balanced'),\n",
        "                   param_grid, cv = 2)\n",
        "\n",
        "#-- Training\n",
        "t0 = time()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "print('Training completed in %0.3fs' % (time() - t0))\n",
        "print(\"\\n\")\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training completed in 3.579s\n",
            "\n",
            "\n",
            "Best parameters combination:\n",
            " C: 1000.0\n",
            " gamma: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggZb7sPA3Nv9"
      },
      "source": [
        "### SVM with ZCR features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTPezyIh3UQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1881358-a7ae-43ee-e7e7-8eaa0eb81cb1"
      },
      "source": [
        "X_train_zcr, X_test_zcr, y_train_zcr, y_test_zcr = load_data(feature_extractor = combo_con_zcr,\n",
        "                                                             normalize = True)\n",
        "\n",
        "#-- Dimensionalità delle Variabili Esplicative\n",
        "X_train_zcr[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKBGf9x43lHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f597b2-967e-40bd-9903-a7afe2383ea2"
      },
      "source": [
        "#-- Parametri da Testare nella Cross-Validation\n",
        "param_grid = {'C': [1e2, 5e2, 1e3],\n",
        "          'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "#-- Inizializzatore della Support Vector Machine\n",
        "clf_zcr = GridSearchCV(SVC(kernel = 'rbf',\n",
        "                       class_weight = 'balanced'),\n",
        "                   param_grid, cv = 2)\n",
        "\n",
        "#-- Training\n",
        "t0 = time()\n",
        "clf_zcr = clf_zcr.fit(X_train_zcr, y_train_zcr)\n",
        "print('Training completed in %0.3fs' % (time() - t0))\n",
        "print(\"\\n\")\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf_zcr.best_estimator_.C))\n",
        "print(' gamma: '+str(clf_zcr.best_estimator_.gamma))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training completed in 2.318s\n",
            "\n",
            "\n",
            "Best parameters combination:\n",
            " C: 500.0\n",
            " gamma: 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU6f0ant3_9Y"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11D41_R04H6o"
      },
      "source": [
        "### SVM without ZCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN-5Iz974KhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc79668-bc00-498d-ba90-425e871f54b4"
      },
      "source": [
        "y_pred = clf.predict(X_test)         #-- Test\n",
        "\n",
        "print(classification_report(y_test,\n",
        "                            y_pred)) #-- Report della Classificazione\n",
        "print(confusion_matrix(y_test,\n",
        "                       y_pred))      #-- Matrice di Confusione"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.65      0.61        17\n",
            "           1       0.33      0.40      0.36        10\n",
            "           2       0.28      0.33      0.30        15\n",
            "           3       0.53      0.42      0.47        19\n",
            "           4       0.36      0.45      0.40        11\n",
            "           5       0.44      0.29      0.35        14\n",
            "           6       0.79      0.79      0.79        14\n",
            "           7       0.80      0.42      0.55        19\n",
            "           8       0.35      0.41      0.38        17\n",
            "           9       0.32      0.43      0.36        14\n",
            "\n",
            "    accuracy                           0.46       150\n",
            "   macro avg       0.48      0.46      0.46       150\n",
            "weighted avg       0.49      0.46      0.47       150\n",
            "\n",
            "[[11  0  0  0  0  0  0  0  0  6]\n",
            " [ 0  4  2  2  0  1  0  0  1  0]\n",
            " [ 2  1  5  3  0  0  0  0  2  2]\n",
            " [ 0  3  7  8  0  0  0  0  0  1]\n",
            " [ 1  1  1  1  5  2  0  0  0  0]\n",
            " [ 1  0  0  1  4  4  1  0  2  1]\n",
            " [ 0  0  0  0  0  0 11  1  2  0]\n",
            " [ 0  0  0  0  2  0  2  8  4  3]\n",
            " [ 0  2  2  0  3  2  0  1  7  0]\n",
            " [ 4  1  1  0  0  0  0  0  2  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkSqjNTI4oup"
      },
      "source": [
        "### SVM con ZCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efVuiM4j4qea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "d1b49d9e-f852-436e-de24-eeb5bd6dc05b"
      },
      "source": [
        "y_pred_zcr = clf_zcr.predict(X_test_zcr) #-- Test\n",
        "\n",
        "print(classification_report(y_test_zcr,\n",
        "                            y_pred_zcr)) #-- Report della Classificazione\n",
        "print(confusion_matrix(y_test_zcr,\n",
        "                       y_pred_zcr))      #-- Matrice di Confusione\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.imshow(confusion_matrix(y_test_zcr,\n",
        "                            y_pred_zcr),\n",
        "           cmap = plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80        17\n",
            "           1       0.53      0.90      0.67        10\n",
            "           2       0.64      0.60      0.62        15\n",
            "           3       0.75      0.63      0.69        19\n",
            "           4       0.47      0.64      0.54        11\n",
            "           5       0.53      0.64      0.58        14\n",
            "           6       0.87      0.93      0.90        14\n",
            "           7       0.89      0.42      0.57        19\n",
            "           8       0.56      0.59      0.57        17\n",
            "           9       0.82      0.64      0.72        14\n",
            "\n",
            "    accuracy                           0.67       150\n",
            "   macro avg       0.68      0.68      0.67       150\n",
            "weighted avg       0.70      0.67      0.67       150\n",
            "\n",
            "[[14  0  1  0  0  0  0  0  0  2]\n",
            " [ 0  9  0  0  1  0  0  0  0  0]\n",
            " [ 0  0  9  2  0  1  1  0  2  0]\n",
            " [ 1  1  1 12  1  2  1  0  0  0]\n",
            " [ 0  2  1  1  7  0  0  0  0  0]\n",
            " [ 0  1  1  0  1  9  0  1  1  0]\n",
            " [ 0  0  0  0  0  0 13  0  1  0]\n",
            " [ 1  1  0  0  2  3  0  8  4  0]\n",
            " [ 0  2  1  1  1  2  0  0 10  0]\n",
            " [ 2  1  0  0  2  0  0  0  0  9]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f001b6ce4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na7MuCoN1NxW"
      },
      "source": [
        "### SVM with mfcc features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fupcU948lqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36c50eba-aafd-4efd-bca4-fbdf3bc1467c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_data(feature_extractor = mfcc,\n",
        "                                             normalize = True)\n",
        "len(X_train)\n",
        "X_train[0].shape\n",
        "\n",
        "param_grid = {'C': [1e2, 5e2, 1e3],\n",
        "              'gamma': [0.005, 0.01, 0.1, 0.5, 1.0], }\n",
        "\n",
        "clf = GridSearchCV(SVC(kernel = 'rbf',\n",
        "                       class_weight = 'balanced'),\n",
        "                    param_grid,\n",
        "                    cv = 2)\n",
        "\n",
        "clf = clf.fit(X_train,\n",
        "            y_train)\n",
        "\n",
        "clf.best_estimator_.C\n",
        "clf.best_estimator_.gamma\n",
        "\n",
        "\n",
        "print('Training completed in %0.3fs' % (time() - t0))\n",
        "print(\"\\n\")\n",
        "print('Best parameters combination:')\n",
        "print(' C: '+str(clf.best_estimator_.C))\n",
        "print(' gamma: '+str(clf.best_estimator_.gamma))\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test,\n",
        "                            y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test,\n",
        "                       y_pred))\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.imshow(confusion_matrix(y_test,\n",
        "                            y_pred),\n",
        "           cmap = plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2033\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1963\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2007\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1976\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1987\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1886\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1842\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1753\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1870\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1813\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1891\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1788\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1556\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1997\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1720\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1692\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1565\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1737\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1760\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1890\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2016\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1493\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1525\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1742\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1866\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1914\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1568\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1627\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1772\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1597\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1801\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1475\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1852\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1953\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1819\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1664\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1962\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1639\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1601\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1288\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1910\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1854\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1807\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1704\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1896\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2042\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2037\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1943\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1640\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1547\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1516\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1609\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1455\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1650\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1960\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1837\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1712\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1774\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1884\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1805\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1713\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2023\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1915\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1931\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1793\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1824\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1579\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1817\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1876\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1958\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1560\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1795\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2036\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1846\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1803\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1945\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2001\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1832\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2039\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1873\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1632\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1806\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2022\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2014\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2045\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1790\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1705\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1673\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1970\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1722\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1850\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1843\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1778\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1433\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1296\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2012\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1911\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1569\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1973\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1434\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1295\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1403\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1634\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1357\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1968\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1593\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1913\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1149\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1610\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1259\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1978\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1965\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2020\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1998\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1858\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1936\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.6/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=2015\n",
            "  n_fft, y.shape[-1]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training completed in 309.161s\n",
            "\n",
            "\n",
            "Best parameters combination:\n",
            " C: 100.0\n",
            " gamma: 0.005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        17\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      1.00      1.00        19\n",
            "           4       1.00      1.00      1.00        11\n",
            "           5       1.00      0.93      0.96        14\n",
            "           6       0.82      1.00      0.90        14\n",
            "           7       1.00      0.95      0.97        19\n",
            "           8       1.00      1.00      1.00        17\n",
            "           9       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.98       150\n",
            "   macro avg       0.98      0.98      0.98       150\n",
            "weighted avg       0.98      0.98      0.98       150\n",
            "\n",
            "[[17  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 10  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 15  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 19  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 13  1  0  0  0]\n",
            " [ 0  0  0  0  0  0 14  0  0  0]\n",
            " [ 0  0  0  0  0  0  1 18  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 17  0]\n",
            " [ 0  0  0  0  0  0  1  0  0 13]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0012dd5e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvxb0DsB1ebD"
      },
      "source": [
        "### Conclusions\r\n",
        "\r\n",
        "\r\n",
        "ZCR improve results of classification, in fact accuracy change from 0.46 (svm without zcr) to 0.67. This means that signal can be distinghuished by the number of zero-crossing. \r\n",
        "Results using mfcc features are the best obtained in term of accuracy (0.97) but this methodss result in being more time consuming than the previous trained. "
      ]
    }
  ]
}